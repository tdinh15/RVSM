{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sparsifying Convolutional Neural Network using RVSM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "import numpy as np\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "# learning_rate = 0.00005\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "# X = tf.zeros([num_input,1])\n",
    "# Y = tf.zeros([1,num_classes])\n",
    "keep_prob = tf.constant(0.2) # dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "    # Reshape to match picture format [Height x Width x Channel]\n",
    "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-fce84427c804>:38: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-7-e16cb5fdfddb>:12: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct model\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define hard thresholding parameters\n",
    "lamb = 0.0005\n",
    "beta = 0.1\n",
    "gamma = lamb/beta\n",
    "\n",
    "# Define loss and optimizers\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "\n",
    "# AdamOptimizer\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "grad = opt.compute_gradients(loss_op)   # grad is a list of tuples of the form (gradient, variable)\n",
    "# grad[2] is the 3rd variable, which is the fully-connected layer we want to modify\n",
    "w = grad[2][1]   # grad[2][1] is the weight w of the fc layer\n",
    "condition = tf.greater(tf.abs(w), np.sqrt(2*gamma))\n",
    "u = tf.where(condition, w, tf.zeros_like(w))   # u = threshold(w)\n",
    "new_grad = grad[2][0] + beta * (w - u)   # replace the current gradient with \\nabla_w Lagrangian\n",
    "grad[2] = (new_grad, w)   # replace the 3rd tuple with (new gradient, w)\n",
    "train_op1 = opt.apply_gradients(grad)   # feed new gradient to the Adam iteration\n",
    "\n",
    "# Evaluate model\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor 'gradients_1/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 1, 32) dtype=float32>,\n",
       "  <tf.Variable 'Variable:0' shape=(5, 5, 1, 32) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_1/Conv2D_1_grad/tuple/control_dependency_1:0' shape=(5, 5, 32, 64) dtype=float32>,\n",
       "  <tf.Variable 'Variable_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_1/MatMul_grad/tuple/control_dependency_1:0' shape=(3136, 1024) dtype=float32>,\n",
       "  <tf.Variable 'Variable_2:0' shape=(3136, 1024) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_1/MatMul_1_grad/tuple/control_dependency_1:0' shape=(1024, 10) dtype=float32>,\n",
       "  <tf.Variable 'Variable_3:0' shape=(1024, 10) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(32,) dtype=float32>,\n",
       "  <tf.Variable 'Variable_4:0' shape=(32,) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_1/BiasAdd_1_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'Variable_5:0' shape=(64,) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_1/Add_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,\n",
       "  <tf.Variable 'Variable_6:0' shape=(1024,) dtype=float32_ref>),\n",
       " (<tf.Tensor 'gradients_1/Add_1_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>,\n",
       "  <tf.Variable 'Variable_7:0' shape=(10,) dtype=float32_ref>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A list of gradients is shown below, confirming that there should be 8 gradients: 4 weights and 4 biases\n",
    "# This also confirms the 3rd tuple is the fc layer we want to modify\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "opt.compute_gradients(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize save function\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 50621.1602, Training Accuracy= 0.156\n",
      "Step 50, Minibatch Loss= 3305.3025, Training Accuracy= 0.797\n",
      "Step 100, Minibatch Loss= 2509.3518, Training Accuracy= 0.875\n",
      "Step 150, Minibatch Loss= 1636.1376, Training Accuracy= 0.891\n",
      "Step 200, Minibatch Loss= 2571.5571, Training Accuracy= 0.875\n",
      "Step 250, Minibatch Loss= 1326.8799, Training Accuracy= 0.914\n",
      "Step 300, Minibatch Loss= 641.3702, Training Accuracy= 0.961\n",
      "Step 350, Minibatch Loss= 419.3207, Training Accuracy= 0.953\n",
      "Step 400, Minibatch Loss= 795.2315, Training Accuracy= 0.922\n",
      "Step 450, Minibatch Loss= 411.6193, Training Accuracy= 0.961\n",
      "Step 500, Minibatch Loss= 311.4163, Training Accuracy= 0.961\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.9609375\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op1, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y,\n",
    "                                                                 keep_prob: 1.0})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n",
    "                                      Y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.0}))\n",
    "    wbar = tf.Variable(w.eval())\n",
    "    saver.save(sess, 'mnist1.chkp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two operations to evaluate the accuracy of the model. \n",
    "# The first one is when w is replaced with u = threshold(w).\n",
    "# The second one is to make sure the code runs correctly. Here u is a reversed threshold of w where large values are pruned off.\n",
    "\n",
    "# Evaluate with u\n",
    "\n",
    "# condition = tf.greater(tf.abs(wbar), 16*np.sqrt(2*gamma))\n",
    "# ubar = tf.where(condition, wbar, tf.zeros_like(wbar))   # This is threshold(wbar)\n",
    "# # weights['wd1'] = ubar\n",
    "# logits_u = conv_net(X, {\n",
    "#                     'wc1': weights['wc1'],\n",
    "#                     'wc2': weights['wc2'],\n",
    "#                     'wd1': ubar,\n",
    "#                     'out': weights['out']\n",
    "#                     }, biases, keep_prob)\n",
    "# prediction_u = tf.nn.softmax(logits_u)\n",
    "# correct_pred_u = tf.equal(tf.argmax(prediction_u, 1), tf.argmax(Y, 1))\n",
    "# accuracy_u = tf.reduce_mean(tf.cast(correct_pred_u, tf.float32))\n",
    "\n",
    "def accuracy_u(wbar,conv_net,mult):\n",
    "    condition = tf.greater(tf.abs(wbar), mult*np.sqrt(2*gamma))\n",
    "    ubar = tf.where(condition, wbar, tf.zeros_like(wbar))   # This is threshold(wbar)\n",
    "    # weights['wd1'] = ubar\n",
    "    logits_u = conv_net(X, {\n",
    "                        'wc1': weights['wc1'],\n",
    "                        'wc2': weights['wc2'],\n",
    "                        'wd1': ubar,\n",
    "                        'out': weights['out']\n",
    "                        }, biases, keep_prob)\n",
    "    prediction_u = tf.nn.softmax(logits_u)\n",
    "    correct_pred_u = tf.equal(tf.argmax(prediction_u, 1), tf.argmax(Y, 1))\n",
    "    return [ubar, tf.reduce_mean(tf.cast(correct_pred_u, tf.float32))]\n",
    "\n",
    "# Evaluate with not u\n",
    "\n",
    "# condition = tf.greater(tf.abs(wbar), np.sqrt(2*gamma))\n",
    "# unot = tf.where(condition, tf.zeros_like(wbar), wbar)   # This is a reversed threshold(wbar)\n",
    "# weights['wd1'] = unot\n",
    "# logits_unot = conv_net(X, weights, biases, keep_prob)\n",
    "# prediction_unot = tf.nn.softmax(logits_unot)\n",
    "# correct_pred_unot = tf.equal(tf.argmax(prediction_unot, 1), tf.argmax(Y, 1))\n",
    "# accuracy_unot = tf.reduce_mean(tf.cast(correct_pred_unot, tf.float32))\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from mnist1.chkp\n",
      "Total elements of w: 3211264\n",
      "Accuracy with w: 0.9609375\n",
      "Accuracy with u at 1.0x threshold: 0.9609375. Sparsity: 8.29%\n",
      "Accuracy with u at 1.5x threshold: 0.96484375. Sparsity: 11.91%\n",
      "Accuracy with u at 2.0x threshold: 0.96484375. Sparsity: 15.85%\n",
      "Accuracy with u at 2.5x threshold: 0.9609375. Sparsity: 19.72%\n",
      "Accuracy with u at 3.0x threshold: 0.9609375. Sparsity: 23.57%\n",
      "Accuracy with u at 3.5x threshold: 0.94921875. Sparsity: 27.35%\n",
      "Accuracy with u at 4.0x threshold: 0.953125. Sparsity: 31.08%\n",
      "Accuracy with u at 4.5x threshold: 0.9453125. Sparsity: 34.73%\n",
      "Accuracy with u at 5.0x threshold: 0.9453125. Sparsity: 38.29%\n",
      "Accuracy with u at 5.5x threshold: 0.9296875. Sparsity: 41.77%\n",
      "Accuracy with u at 6.0x threshold: 0.94140625. Sparsity: 45.16%\n",
      "Accuracy with u at 6.5x threshold: 0.93359375. Sparsity: 48.43%\n",
      "Accuracy with u at 7.0x threshold: 0.94921875. Sparsity: 51.61%\n",
      "Accuracy with u at 7.5x threshold: 0.94140625. Sparsity: 54.68%\n",
      "Accuracy with u at 8.0x threshold: 0.9296875. Sparsity: 57.63%\n",
      "Accuracy with u at 8.5x threshold: 0.91015625. Sparsity: 60.47%\n",
      "Accuracy with u at 9.0x threshold: 0.90234375. Sparsity: 63.19%\n",
      "Accuracy with u at 9.5x threshold: 0.89453125. Sparsity: 65.78%\n",
      "Accuracy with u at 10.0x threshold: 0.87890625. Sparsity: 68.29%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, 'mnist1.chkp')\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    \n",
    "    # Evaluate with w\n",
    "    acc = sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n",
    "                                      Y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.0})\n",
    "    print('Total elements of w: {}'.format(size_w))\n",
    "    print('Accuracy with w: {:.8}'.format(acc))    \n",
    "    \n",
    "    # Evaluate with u\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for j in range(2,21):\n",
    "        mult = j/2\n",
    "        [ubar, acc_u] = sess.run(accuracy_u(wbar,conv_net,mult), feed_dict={X: mnist.test.images[:256],\n",
    "                                          Y: mnist.test.labels[:256],\n",
    "                                          keep_prob: 1.0})\n",
    "        size_w = 7*7*64*1024\n",
    "        zeros_u = size_w - np.count_nonzero(ubar)\n",
    "        sparse_u = zeros_u / size_w * 100\n",
    "        print('Accuracy with u at {}x threshold: {:.8}'.format(mult, acc_u) + '. Sparsity: {:.2f}%'.format(sparse_u))\n",
    "        x.append(sparse_u)\n",
    "        y.append(acc_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('sparsity of u')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('sparsity vs accuracy of u')\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
